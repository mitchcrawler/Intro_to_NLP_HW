{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Implementation 2\n",
    "\n",
    "The same use case as in [m7_1_Implementation_regex](m7_1_Implementation_regex.ipynb) can be implemented using pyConText.\n",
    "\n",
    "In order to benefit from the functionality provided by the framwork, you need to ensure that the modules that you use can operate using the classes provided by the framework. For that purpose, [pyContText](https://pypi.python.org/pypi/pyConTextNLP/0.6.2.0) functionality has to be encapsulated into a Wrapper class [wrapperPyConText](wrapperPyConText_doc.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeUtils import Document\n",
    "from pipeUtils import Annotation\n",
    "\n",
    "from wrapperPyConText import ConTextPipe\n",
    "from PyRuSH.RuSH import RuSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using our framework, the first lines of this implementation are identical to the regex implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document()\n",
    "\n",
    "doc.load_document_from_file('data/test.txt')\n",
    "doc.load_annotations_from_brat('data/test.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As discussed in the previous modules, pyConText operates at a sentence level, so prior to sending documents to pyConText, we need to break the text into sentences. \n",
    "\n",
    "[pyRuSH](https://pypi.python.org/pypi/PyRuSH) is a sentence segmentation package that works well on clinical data. It applying pyRuSH segmenter creates a list of spans for each sentence that can be converted to a list of annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rules='KB/rush_rules.tsv'\n",
    "sentence_segmenter = RuSH(sentence_rules)\n",
    "\n",
    "sentences=sentence_segmenter.segToSentenceSpans(doc.text)\n",
    "i=0\n",
    "for sentence in sentences:\n",
    "    i=i+1  #incrementing the index\n",
    "    doc.annotations.append(Annotation(start_index=sentence.begin,\n",
    "                                      end_index=sentence.end, \n",
    "                                      type=\"Sentence\", \n",
    "                                      ann_id='Sent_'+str(i)))\n",
    "    \n",
    "print(doc.toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying context rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_rules='''\n",
    "Comments: ''\n",
    "Direction: ''\n",
    "Lex: pain\n",
    "Regex: ''\n",
    "Type: Depression_Symptom\n",
    "---\n",
    "Comments: ''\n",
    "Direction: ''\n",
    "Lex: depression\n",
    "Regex: 'depres\\\\w+'\n",
    "Type: Depression_Symptom\n",
    "---\n",
    "Comments: ''\n",
    "Direction: ''\n",
    "Lex: suicidal\n",
    "Regex: 'suicidal\\\\s*ideation'\n",
    "Type: Depression_Symptom\n",
    "'''\n",
    "# context rules are often lengthy, you can point \n",
    "#    context_rules to an external rule files instead\n",
    "context_rules='''Comments: ''\n",
    "Direction: forward\n",
    "Lex: 'no'\n",
    "Regex: '\\\\bno\\\\b'\n",
    "Type: Negation\n",
    "---\n",
    "Comments: ''\n",
    "Direction: forward\n",
    "Lex: 'denies'\n",
    "Regex: ''\n",
    "Type: Negation\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our rules specified and our sentences segmented. Let's apply rules on each sentence and add new annotations to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context_pipe = ConTextPipe(target_rules, context_rules)\n",
    "new_anns = []\n",
    "for a in doc.annotations:\n",
    "    if a.type == \"Sentence\":\n",
    "        b = context_pipe.process(a, doc.text)\n",
    "        doc.annotations.extend(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(doc.toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of pyContext implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
